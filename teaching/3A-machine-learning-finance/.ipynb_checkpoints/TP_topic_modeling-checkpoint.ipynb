{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# TP sur le topic modeling (énoncé)\n",
    "\n",
    "François HU - Data scientist au DataLab de la Société Générale Assurances - *19/11/19* - https://nbviewer.jupyter.org/github/curiousML/DSA/tree/master/text_mining/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div id=\"my_id_menu_nb\">run previous cell, wait for 2 seconds</div>\n",
       "<script>\n",
       "function repeat_indent_string(n){\n",
       "    var a = \"\" ;\n",
       "    for ( ; n > 0 ; --n)\n",
       "        a += \"    \";\n",
       "    return a;\n",
       "}\n",
       "// look up into all sections and builds an automated menu //\n",
       "var update_menu_string = function(begin, lfirst, llast, sformat, send, keep_item, begin_format, end_format) {\n",
       "    var anchors = document.getElementsByClassName(\"section\");\n",
       "    if (anchors.length == 0) {\n",
       "        anchors = document.getElementsByClassName(\"text_cell_render rendered_html\");\n",
       "    }\n",
       "    var i,t;\n",
       "    var text_menu = begin;\n",
       "    var text_memo = \"<pre>\\nlength:\" + anchors.length + \"\\n\";\n",
       "    var ind = \"\";\n",
       "    var memo_level = 1;\n",
       "    var href;\n",
       "    var tags = [];\n",
       "    var main_item = 0;\n",
       "    var format_open = 0;\n",
       "    for (i = 0; i <= llast; i++)\n",
       "        tags.push(\"h\" + i);\n",
       "\n",
       "    for (i = 0; i < anchors.length; i++) {\n",
       "        text_memo += \"**\" + anchors[i].id + \"--\\n\";\n",
       "\n",
       "        var child = null;\n",
       "        for(t = 0; t < tags.length; t++) {\n",
       "            var r = anchors[i].getElementsByTagName(tags[t]);\n",
       "            if (r.length > 0) {\n",
       "child = r[0];\n",
       "break;\n",
       "            }\n",
       "        }\n",
       "        if (child == null) {\n",
       "            text_memo += \"null\\n\";\n",
       "            continue;\n",
       "        }\n",
       "        if (anchors[i].hasAttribute(\"id\")) {\n",
       "            // when converted in RST\n",
       "            href = anchors[i].id;\n",
       "            text_memo += \"#1-\" + href;\n",
       "            // passer à child suivant (le chercher)\n",
       "        }\n",
       "        else if (child.hasAttribute(\"id\")) {\n",
       "            // in a notebook\n",
       "            href = child.id;\n",
       "            text_memo += \"#2-\" + href;\n",
       "        }\n",
       "        else {\n",
       "            text_memo += \"#3-\" + \"*\" + \"\\n\";\n",
       "            continue;\n",
       "        }\n",
       "        var title = child.textContent;\n",
       "        var level = parseInt(child.tagName.substring(1,2));\n",
       "\n",
       "        text_memo += \"--\" + level + \"?\" + lfirst + \"--\" + title + \"\\n\";\n",
       "\n",
       "        if ((level < lfirst) || (level > llast)) {\n",
       "            continue ;\n",
       "        }\n",
       "        if (title.endsWith('¶')) {\n",
       "            title = title.substring(0,title.length-1).replace(\"<\", \"&lt;\")\n",
       "         .replace(\">\", \"&gt;\").replace(\"&\", \"&amp;\");\n",
       "        }\n",
       "        if (title.length == 0) {\n",
       "            continue;\n",
       "        }\n",
       "\n",
       "        while (level < memo_level) {\n",
       "            text_menu += end_format + \"</ul>\\n\";\n",
       "            format_open -= 1;\n",
       "            memo_level -= 1;\n",
       "        }\n",
       "        if (level == lfirst) {\n",
       "            main_item += 1;\n",
       "        }\n",
       "        if (keep_item != -1 && main_item != keep_item + 1) {\n",
       "            // alert(main_item + \" - \" + level + \" - \" + keep_item);\n",
       "            continue;\n",
       "        }\n",
       "        while (level > memo_level) {\n",
       "            text_menu += \"<ul>\\n\";\n",
       "            memo_level += 1;\n",
       "        }\n",
       "        text_menu += repeat_indent_string(level-2);\n",
       "        text_menu += begin_format + sformat.replace(\"__HREF__\", href).replace(\"__TITLE__\", title);\n",
       "        format_open += 1;\n",
       "    }\n",
       "    while (1 < memo_level) {\n",
       "        text_menu += end_format + \"</ul>\\n\";\n",
       "        memo_level -= 1;\n",
       "        format_open -= 1;\n",
       "    }\n",
       "    text_menu += send;\n",
       "    //text_menu += \"\\n\" + text_memo;\n",
       "\n",
       "    while (format_open > 0) {\n",
       "        text_menu += end_format;\n",
       "        format_open -= 1;\n",
       "    }\n",
       "    return text_menu;\n",
       "};\n",
       "var update_menu = function() {\n",
       "    var sbegin = \"\";\n",
       "    var sformat = '<a href=\"#__HREF__\">__TITLE__</a>';\n",
       "    var send = \"\";\n",
       "    var begin_format = '<li>';\n",
       "    var end_format = '</li>';\n",
       "    var keep_item = -1;\n",
       "    var text_menu = update_menu_string(sbegin, 2, 4, sformat, send, keep_item,\n",
       "       begin_format, end_format);\n",
       "    var menu = document.getElementById(\"my_id_menu_nb\");\n",
       "    menu.innerHTML=text_menu;\n",
       "};\n",
       "window.setTimeout(update_menu,2000);\n",
       "            </script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from jyquickhelper import add_notebook_menu\n",
    "add_notebook_menu()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Introduction**\n",
    "\n",
    "Les topic models (*modèles thématiques* en français) sont une famille de modèles qui sont capables de découvrir les topics (*thèmes* en français) d'une collection de documents textuels. Dans ce contexte, le terme \"**topic**\" désigne des groupes de mots qui se retrouvent souvent ensemble dans un même document. Par exemple, dans un recueil d'articles de journaux, un topic model peut identifier un topic composé des mots :\n",
    "- \"homme politique\", \"droit\" et \"parlement\", et un autre caractérisé par \n",
    "- \"joueur\", \"match\" et \"carton rouge\"\n",
    "\n",
    "Les topics modeling ne peuvent pas affecter un titre à ces topics : c'est notre tâche d'interpréter ces topics et de leur donner des étiquettes telles que \"politique\" et \"football\".\n",
    "\n",
    "L'un des modèles les plus populaires est le LDA. Le LDA (cf. <font color = \"red\">sections précédentes</font>) est un modèle génératif qui considère chaque document comme un mélange de topics. Ce sont ces topics qui seront en charge de générer les mots. Par exemple, le topic \"football\" générera le mot \"pénalité\" avec une probabilité élevée, tandis que le topic \"politique\" aura une probabilité beaucoup plus élevée pour générer le mot \"politicien\" que pour générer le mot \"pénalité\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Données : Grand Débat National\n",
    "\n",
    "- L'un des contextes où la modélisation des topics est très utile est celui des questions ouvertes. Il nous permet d'explorer la variation des topics abordés dans les réponses des gens. \n",
    "\n",
    "- Dans ce notebook nous allons explorer un ensemble complet de réponses du [Grand Débat National](https://granddebat.fr/), le débat public organisé par le président Macron. Le but du débat était de mieux comprendre les besoins et les opinions des Français suite aux manifestations des gilets jaunes. Les résultats de ce débat sont maintenant disponibles sous forme de [données ouvertes](https://granddebat.fr/pages/donnees-ouvertes). \n",
    "\n",
    "- Nous allons tout d'abord télécharger un des fichiers csv sur la transition écologique et charger le contenu dans un dataframe [pandas](https://pandas.pydata.org/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 3.1. Charger les données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/miniconda3/envs/xeus-cling2/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3049: DtypeWarning: Columns (6) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# indiquer le chemin du fichier\n",
    "chemin = \"https://raw.githubusercontent.com/curiousML/DSA/master/text_mining/data/LA_TRANSITION_ECOLOGIQUE.csv\"\n",
    "#\"/chemin/menant/a/LA_TRANSITION_ECOLOGIQUE.csv\"\n",
    "\n",
    "# notre dataframe\n",
    "df = pd.read_csv(chemin, error_bad_lines=False, warn_bad_lines=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Chacune des lignes de ce dataframe ``df`` contient des réponses répondant à une liste de questions sur la transition écologique. Certaines de ces questions sont à choix multiples, tandis que d'autres sont des questions ouvertes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['reference', 'title', 'createdAt', 'publishedAt', 'updatedAt',\n",
       "       'trashed', 'trashedStatus', 'authorId', 'authorType', 'authorZipCode',\n",
       "       'Quel est aujourd'hui pour vous le problème concret le plus important dans le domaine de l'environnement ?',\n",
       "       'Que faudrait-il faire selon vous pour apporter des réponses à ce problème ?',\n",
       "       'Diriez-vous que votre vie quotidienne est aujourd'hui touchée par le changement climatique ?',\n",
       "       'Si oui, de quelle manière votre vie quotidienne est-elle touchée par le changement climatique ?',\n",
       "       'À titre personnel, pensez-vous pouvoir contribuer à protéger l'environnement ?',\n",
       "       'Si oui, que faites-vous aujourd'hui pour protéger l'environnement et/ou que pourriez-vous faire ?',\n",
       "       'Qu'est-ce qui pourrait vous inciter à changer vos comportements comme par exemple mieux entretenir et régler votre chauffage, modifier votre manière de conduire ou renoncer à prendre votre véhicule pour de très petites distances ?',\n",
       "       'Quelles seraient pour vous les solutions les plus simples et les plus supportables sur un plan financier pour vous inciter à changer vos comportements ?',\n",
       "       'Par rapport à votre mode de chauffage actuel, pensez-vous qu'il existe des solutions alternatives plus écologiques ?',\n",
       "       'Si oui, que faudrait-il faire pour vous convaincre ou vous aider à changer de mode de chauffage ?',\n",
       "       'Avez-vous pour vos déplacements quotidiens la possibilité de recourir à des solutions de mobilité alternatives à la voiture individuelle comme les transports en commun, le covoiturage, l'auto-partage, le transport à la demande, le vélo, etc. ?',\n",
       "       'Si oui, que faudrait-il faire pour vous convaincre ou vous aider à utiliser ces solutions alternatives ?',\n",
       "       'Si non, quelles sont les solutions de mobilité alternatives que vous souhaiteriez pouvoir utiliser ?',\n",
       "       'Et qui doit selon vous se charger de vous proposer ce type de solutions alternatives ?',\n",
       "       'Que pourrait faire la France pour faire partager ses choix en matière d'environnement au niveau européen et international ?',\n",
       "       'Y a-t-il d'autres points sur la transition écologique sur lesquels vous souhaiteriez vous exprimer ?'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Nous nous focaliserons sur la dernière question : ``Y a-t-il d'autres points sur la transition écologique sur lesquels vous souhaiteriez vous exprimer ?`` car elle donne le plus de liberté aux personnes.\n",
    "\n",
    "Nous espérons que notre modèle LDA nous aidera à analyser les topics sur lesquels portent leurs réponses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0               Multiplier les centrales géothermiques\n",
       "1    Les problèmes auxquels se trouve confronté l’e...\n",
       "2                                                  NaN\n",
       "3                                                  NaN\n",
       "4      Une vrai politique écologique et non économique\n",
       "5    Les bonnes idées ne grandissent que par le par...\n",
       "6    Pédagogie dans ce sens là dés la petite école ...\n",
       "7                                                  NaN\n",
       "8    faire de l'écologie incitative et non punitive...\n",
       "9    Développer le ferroutage pour les poids lourds...\n",
       "Name: Y a-t-il d'autres points sur la transition écologique sur lesquels vous souhaiteriez vous exprimer ?, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"Y a-t-il d'autres points sur la transition écologique sur lesquels vous souhaiteriez vous exprimer ?\"\n",
    "df[question].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 3.2. Nettoyer et vectoriser les documents\n",
    "\n",
    "Avant d'entraîner notre modèle LDA, nous avons besoin de tokenizer notre texte. Nous allons tokenizer grâce à la librarie [spaCy](https://spacy.io/) car nous allons effectuer seulement quelques prétraitements de base. Nous allons juste initialiser un modèle vierge pour la langue française."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.blank(\"fr\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Supprimons toutes les lignes du dataframe qui n'ont pas de réponse pour notre question (les `NaN`s ci-dessus). Ce nouveau dataframe s'appellera ``textes``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "textes = ... # A REMPLIR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Ensuite, nous utilisons spaCy pour effectuer notre premier prétraitement :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 14.2 s, sys: 521 ms, total: 14.7 s\n",
      "Wall time: 15.1 s\n"
     ]
    }
   ],
   "source": [
    "%time spacy_docs = list(nlp.pipe(textes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Nous avons maintenant une liste de documents spaCy. Nous allons transformer chaque document spaCy en une liste de tokens. Au lieu des tokens originaux, nous allons travailler avec les lemmes à la place. Cela permettra à notre modèle de mieux généraliser, car il pourra \"voir\" que \"géothermiques\" et \"géothermique\" représentent la même signification. Voici la liste complète des prétraitements : \n",
    " \n",
    "- supprimer tous les **mots de moins de 3 caractères**,\n",
    "- supprimer tous les **stop-words**, et\n",
    "- **lemmatiser** les mots restants et,\n",
    "- mettre ces mots en **minuscules**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['multiplier', 'centrales', 'géothermiques'], ['problèmes', 'trouve', 'confronté', 'ensemble', 'planète', 'dénoncent', 'parfait', 'désordre', 'gilets', 'jaunes', 'france', 'surpopulation', 'mondiale', 'population', 'passée', 'd’1,5', 'milliards', 'habitants', '1900', 'milliards', '2020', 'montera', 'bientôt', 'milliards', '2040', 'progrès', 'communication', 'village', 'mondial', 'individu', 'fond', 'asie', 'fond', 'afrique', 'passant', 'quartiers', 'campagnes', 'pays', 'aspire', 'vivre', 'blâmer', 'lotis', 'concitoyens', 'logement', 'nourriture', 'biens', 'consommation', 'déplacement', 'mère', 'problèmes', 'solution', 'problèmes', 'stabilisation', 'croissance', 'démographique', 'partage', 'richesses', 'partage', 'terres', 'partage', 'protection', 'biodiversité', 'règlement', 'conflits', 'lutte', 'déforestation', 'lutte', 'dérèglement', 'climatique', 'règlement', 'conflits', 'stabilisation', 'migrations', 'concurrence', 'commerciale', 'mondiale', 'etc.', 'française', 'européenne', 'mondiale', 'france', 'jouer', 'rôle', 'moteur', 'autour', 'déroulera', 'grand', 'débat', 'paraît', 'anecdotique'], ['vrai', 'politique', 'écologique', 'économique']]\n"
     ]
    }
   ],
   "source": [
    "docs = [[t.lemma_.lower() for t in doc if len(t.orth_) > 3 and not t.is_stop] for doc in spacy_docs]\n",
    "print(docs[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Afin de conserver un peu les ordres des mots dans notre modélisation, nous allons tenir en compte les bigrammes fréquents. Pour cela, nous allons utiliser la bibliothèque [Gensim](https://radimrehurek.com/gensim/). Nous tenons à remarquer que la bibliothèse Gensim est une excellente bibliothèque NLP pour les topics modeling. \n",
    "\n",
    "Voici le processus retenu : \n",
    "\n",
    "- Nous identifions d'abord les bigrammes fréquents dans le corpus, \n",
    "- puis nous les ajoutons à la liste des tokens pour les documents dans lesquels ils apparaissent. Cela signifie que les bigrammes ne seront pas dans leur position correcte dans le texte, mais cela ne pose pas de soucis : les topic models sont des modèles de bag-of-words (*sac-de-mots* en français) qui ignorent la position des mots de toute façon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from gensim.models import Phrases\n",
    "\n",
    "bigram = Phrases(docs, min_count=10)\n",
    "\n",
    "for idx in range(len(docs)):\n",
    "    for token in bigram[docs[idx]]:\n",
    "        if '_' in token:  # les bigrammes peuvent être reconnus par \"_\" qui concatène les mots\n",
    "            # A REMPLIR (DEBUT)\n",
    "            ...\n",
    "            # (FIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['vrai', 'politique', 'écologique', 'économique']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Passons aux dernières étapes du prétraitement spécifique à Gensim. Nous allons tout d'abord créer une représentation dictionnaire des documents. Ce dictionnaire mappera chaque mot à un identifiant unique et nous aidera à créer des représentations en sac-de-mot de chaque document. Ces représentations en sac-de-mots contiennent les identificateurs des mots du document ainsi que leur fréquence. De plus, nous pouvons supprimer les mots les moins fréquents et les plus fréquents du vocabulaire. Cela améliorera la qualité de notre modèle et accélèrera son entraînement. La fréquence minimale d'un mot est exprimée en nombre absolu, la fréquence maximale est la proportion de documents dans lesquels un mot peut figurer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique words in original documents : 43652\n",
      "Number of unique words after removing rare and common words : 17759\n",
      "Example representation of document 3 : [(85, 1), (86, 1), (87, 1), (88, 1)]\n"
     ]
    }
   ],
   "source": [
    "from gensim.corpora import Dictionary\n",
    "\n",
    "dictionary = Dictionary(docs)\n",
    "print('Number of unique words in original documents :', len(dictionary))\n",
    "\n",
    "dictionary.filter_extremes(no_below=3, no_above=0.25)\n",
    "print('Number of unique words after removing rare and common words :', len(dictionary))\n",
    "\n",
    "print(\"Example representation of document 3 :\", dictionary.doc2bow(docs[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Ensuite, nous créons des représentations en sac de mots pour chaque document du corpus voir la méthode [doc2bow](https://radimrehurek.com/gensim/corpora/dictionary.html) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "corpus = [ ... for doc in docs] # A REMPLIR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 3.3. Topic Modeling avec LDA\n",
    "\n",
    "Maintenant, il est temps d'entraîner notre LDA ! Pour ce faire, nous utilisons les paramètres suivants : \n",
    "\n",
    "- **corpus** : les représentations en sac-de-mots de nos documents\n",
    "- **id2token** : le mappage des index aux mots\n",
    "- **num_topics** : le nombre de topics que le modèle doit identifier (fixons à <font color = \"red\"><b>10</b></font>)\n",
    "- **chunksize** : le nombre de documents que le modèle voit à chaque mise à jour (fixons à <font color = \"red\"><b>1 000</b></font>)\n",
    "- **passes** : le nombre de fois où nous montrons le corpus total au modèle pendant l'entraînement (fixons à <font color = \"red\"><b>5</b></font>)\n",
    "- **random_state** : nous utilisons une graine pour assurer la reproductibilité (fixons à <font color = \"red\"><b>1</b></font>)\n",
    "\n",
    "Sur un corpus de cette taille, l'entraînement dure généralement une ou deux minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 43.4 s, sys: 478 ms, total: 43.9 s\n",
      "Wall time: 44.5 s\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import LdaModel\n",
    "\n",
    "%time model = LdaModel(...) # A REMPLIR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 3.3. Résultats et visualisation\n",
    "\n",
    "Voyons ce que le modèle a appris. Pour ce faire, affichons les dix mots les plus caractéristiques pour chacun des topics. Nous obeservons déjà des tendances intéressantes : si certains topics sont plus généraux (comme le topic 3), d'autres font référence à des topics très pertinents : \n",
    "- véhicules électriques (**topic 1**), \n",
    "- énergie (alternative) (**topic 2**), \n",
    "- agriculture (**topic 6**), \n",
    "- déchets et recyclage (**topic 7**) et \n",
    "- fiscalité (**topic 9**)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********\n",
      "* topic 1 *\n",
      "***********\n",
      "1 : 0.052*\"produits\" + 0.021*\"agriculture\" + 0.017*\"interdire\" + 0.014*\"animaux\" + 0.012*\"pesticides\" + 0.011*\"agriculteurs\" + 0.010*\"production\" + 0.009*\"consommation\" + 0.009*\"santé\" + 0.008*\"favoriser\"\n",
      "\n",
      "***********\n",
      "* topic 2 *\n",
      "***********\n",
      "2 : 0.010*\"climatique\" + 0.007*\"problème\" + 0.007*\"planète\" + 0.006*\"population\" + 0.006*\"réchauffement\" + 0.005*\"années\" + 0.005*\"grand\" + 0.005*\"changement\" + 0.004*\"problèmes\" + 0.004*\"croissance\"\n",
      "\n",
      "***********\n",
      "* topic 3 *\n",
      "***********\n",
      "3 : 0.024*\"protection\" + 0.018*\"environnement\" + 0.017*\"pollueur\" + 0.015*\"grande_distribution\" + 0.013*\"distribution\" + 0.013*\"payeur\" + 0.011*\"arrêtons\" + 0.011*\"principe\" + 0.010*\"obsolescence\" + 0.009*\"grande\"\n",
      "\n",
      "***********\n",
      "* topic 4 *\n",
      "***********\n",
      "4 : 0.012*\"villes\" + 0.012*\"déchets\" + 0.012*\"entreprises\" + 0.011*\"grandes\" + 0.009*\"zones\" + 0.006*\"ville\" + 0.006*\"obliger\" + 0.006*\"faut\" + 0.006*\"faire\" + 0.006*\"centre\"\n",
      "\n",
      "***********\n",
      "* topic 5 *\n",
      "***********\n",
      "5 : 0.035*\"vitesse\" + 0.019*\"limitation\" + 0.017*\"routes\" + 0.015*\"sécurité\" + 0.015*\"lieu\" + 0.012*\"route\" + 0.012*\"gouvernement\" + 0.009*\"temps\" + 0.009*\"disparaissent\" + 0.008*\"politique\"\n",
      "\n",
      "***********\n",
      "* topic 6 *\n",
      "***********\n",
      "6 : 0.023*\"faut\" + 0.017*\"faire\" + 0.008*\"terme\" + 0.008*\"écologie\" + 0.008*\"monde\" + 0.008*\"pays\" + 0.007*\"france\" + 0.007*\"changer\" + 0.007*\"planète\" + 0.007*\"sommes\"\n",
      "\n",
      "***********\n",
      "* topic 7 *\n",
      "***********\n",
      "7 : 0.031*\"faire\" + 0.015*\"pollueurs\" + 0.013*\"gros\" + 0.010*\"payer\" + 0.010*\"exemple\" + 0.007*\"grands\" + 0.007*\"montrer\" + 0.006*\"grosses\" + 0.006*\"pollution\" + 0.006*\"nuit\"\n",
      "\n",
      "***********\n",
      "* topic 8 *\n",
      "***********\n",
      "8 : 0.038*\"énergie\" + 0.032*\"nucléaire\" + 0.028*\"énergies\" + 0.016*\"production\" + 0.015*\"centrales\" + 0.015*\"électricité\" + 0.014*\"renouvelables\" + 0.014*\"développer\" + 0.013*\"éoliennes\" + 0.012*\"panneaux\"\n",
      "\n",
      "***********\n",
      "* topic 9 *\n",
      "***********\n",
      "9 : 0.023*\"voiture\" + 0.019*\"véhicules\" + 0.016*\"voitures\" + 0.015*\"taxer\" + 0.014*\"électrique\" + 0.013*\"transport\" + 0.011*\"véhicule\" + 0.011*\"diesel\" + 0.010*\"taxe\" + 0.010*\"transports\"\n",
      "\n",
      "***********\n",
      "* topic 10 *\n",
      "***********\n",
      "10 : 0.047*\"transition\" + 0.044*\"écologique\" + 0.029*\"transition_écologique\" + 0.012*\"place\" + 0.012*\"entreprises\" + 0.010*\"investissement\" + 0.008*\"faut\" + 0.007*\"taxes\" + 0.007*\"mettre\" + 0.007*\"mise\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for (topic, words) in model.print_topics():\n",
    "    print(\"***********\")\n",
    "    print(\"* topic\", topic+1, \"*\")\n",
    "    print(\"***********\")\n",
    "    print(topic+1, \":\", words)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Une autre façon d'observer les topics est de les **visualiser**. Ceci peut être fait avec la bibliothèque [pyLDAvis](https://github.com/bmabey/pyLDAvis). PyLDAvis nous montrera à quel point les sujets sont populaires dans notre corpus, à quel point les sujets sont similaires et quels sont les mots les plus importants pour ce sujet. Notez qu'il est important de définir ``sort_topics = False`` sur l'appel à pyLDAvis. Si vous ne le faites pas, les sujets seront classés différemment de ceux de Gensim. Cela peut prendre quelques minutes pour charger."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import pyLDAvis.gensim\n",
    "import warnings\n",
    "\n",
    "pyLDAvis.enable_notebook()\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n",
    "\n",
    "pyLDAvis.gensim.prepare(model, corpus, dictionary, sort_topics=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Enfin, examinons les topics que le modèle reconnaît dans certains des documents individuels. Nous voyons ici comment LDA tend à attribuer une probabilité élevée à un faible nombre de sujets pour chaque document, ce qui rend ses résultats très interprétables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********\n",
      "* doc 1   *\n",
      "***********\n",
      "Multiplier les centrales géothermiques\n",
      "[(5, 0.27430695), (8, 0.5254362)]\n",
      "\n",
      "***********\n",
      "* doc 2   *\n",
      "***********\n",
      "Les problèmes auxquels se trouve confronté l’ensemble de la planète et que dénoncent, dans le plus parfait désordre, les gilets jaunes de France ne sont-ils pas dus, avant tout, à la surpopulation mondiale ? Cette population est passée d’1,5 milliards d’habitants en 1900 à 7 milliards en 2020 et montera bientôt à 10 milliards vers 2040.  Avec les progrès de la communication dans ce village mondial, chaque individu, du fin fond de l’Asie au fin fond de l’Afrique, en passant par les « quartiers » et les « campagnes » de notre pays, aspire à vivre – et on ne peu l’en blâmer – comme les moins mal lotis de nos concitoyens (logement, nourriture, biens de consommation, déplacement,etc.).  Voilà la mère de tous les problèmes. Si tel est bien le cas, la solution à tous les problèmes (stabilisation de la croissance démographique, partage des richesses, partage des terres, partage de l’eau, protection de la biodiversité, règlement des conflits, lutte contre la déforestation, lutte contre dérèglement climatique, règlement des conflits, stabilisation des migrations, concurrence commerciale mondiale, etc.) ne sera ni française, ni européenne, mais mondiale. La France se doit d’y jouer un rôle moteur.  Le reste, autour duquel se déroulera « le Grand débat », paraît assez anecdotique.\n",
      "[(2, 0.8235213)]\n",
      "\n",
      "***********\n",
      "* doc 3   *\n",
      "***********\n",
      "Une vrai politique écologique et non économique\n",
      "[(6, 0.8199753)]\n",
      "\n",
      "***********\n",
      "* doc 4   *\n",
      "***********\n",
      "Les bonnes idées ne grandissent que par le partage.\n",
      "\n",
      "En ces jours pénibles où s'affrontent le peuple et ceux entre lesquels ils ont remis leur sort. (tous concernés puis qu’élus).\n",
      "\n",
      "Une idée qui flotte en ce moment sur la mobilité propre dans les zones non ou mal desservies et qui est encore expérimentale dans quelques communes.\n",
      "\n",
      "L'avenir  est entre vos mains et les nôtres. Pourquoi ne pas planifier l'installation de flotte de véhicules électriques partagés en location, dans ces zones isolées.\n",
      "\n",
      "En construisant un partenariat avec : état, région, département, commune ou communauté, professionnel de la location, entreprises locales, constructeurs de véhicules, les bailleurs sociaux, pour la mise en place. Avec l'apport financier de la TICPE qui baissera au fil de la décroissance de la consommation, il faudra penser à la déconnecter du budget de fonctionnement de l'état !\n",
      "\n",
      "Avec un forfait de location pour les utilisateurs, adapté à leur ressources et peut être tout simplement basé sur leurs dépenses de mobilité actuelles. Ainsi pas d'investissements inaccessibles pour eux.\n",
      "\n",
      "Tout le monde y gagnerait, cela  pourrait prendre l'image du relais de poste comme par le passé et réglerait le problème d'autonomie actuel et engendrerait quelques emplois de service, nouveaux.\n",
      "[(2, 0.13684697), (4, 0.12634256), (6, 0.16841982), (9, 0.2015315), (10, 0.36116502)]\n",
      "\n",
      "***********\n",
      "* doc 5   *\n",
      "***********\n",
      "Pédagogie dans ce sens là dés la petite école pour sensibilisation via les parcs naturels . Les enfants doivent devenir des prescripteurs  pour les générations futures . Il y a urgence\n",
      "[(2, 0.13640082), (4, 0.2681016), (6, 0.5488043)]\n",
      "\n",
      "***********\n",
      "* doc 6   *\n",
      "***********\n",
      "faire de l'écologie incitative et non punitive on n'est pas des gosses à qui on distribue des bonnes ou mauvaises notes\n",
      "[(2, 0.46371236), (10, 0.44722226)]\n",
      "\n",
      "***********\n",
      "* doc 7   *\n",
      "***********\n",
      "Développer le ferroutage pour les poids lourds, Instaurer une vignette pour les poids lourds étrangers qui traversent la France\n",
      "[(9, 0.8150414), (10, 0.13784769)]\n",
      "\n",
      "***********\n",
      "* doc 8   *\n",
      "***********\n",
      "- Favoriser le tri des déchets en mettant en place une redevance incitatrice et non punitive,\n",
      "- Arrêt d'une écologie punitive à base de taxes qui est néfaste à la compréhension d'une écologie intelligente, adaptée et durable.\n",
      "- Revoir la politique de pose des panneaux solaire en Ferme qui en fait gâche des terrains et sert plus à récolter des taxes pour les caisses des collectivités,\n",
      "- Revoir la politique de mise en place des éoliennes qui ne sont pas adaptées, peu rentable (< 30%) et qui produisent des effets néfastes par du bruit et des infra-ondes,\n",
      "- Arrêt du rachat, à des prix exorbitants, de l'énergie produite par des panneaux solaire, par des éoliennes ou par tout autre moyen dit propre (Bio-masse, hydraulique),\n",
      "- Favoriser le développement de la bio-masse,\n",
      "- Développer le stockage intelligent de l'énergie,\n",
      "- Réaliser une grande opération pour assurer l'isolation des bâtiments énergivores,\n",
      "- Éteindre les éclairages la nuit,\n",
      "- Développer les transports en site propre.\n",
      "[(1, 0.18159804), (8, 0.45110586), (10, 0.21095155)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Nous en affichons que 8\n",
    "i = 0\n",
    "for (text, doc) in zip(texts[:8], docs[:8]):\n",
    "    i += 1\n",
    "    print(\"***********\")\n",
    "    print(\"* doc\", i, \"  *\")\n",
    "    print(\"***********\")\n",
    "    print(text)\n",
    "    print([(topic+1, prob) for (topic, prob) in model[dictionary.doc2bow(doc)] if prob > 0.1])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Conclusion**\n",
    "\n",
    "De nombreuses collections de textes non structurés ne sont pas accompagnées d'étiquettes. Les topic models (*modèles thématiques* en français) tels que le LDA sont une technique utile pour découvrir les topics les plus importants dans ces documents. **Gensim** facilite l'apprentissage sur ces sujets et **pyLDAvis** présente les résultats d'une manière visuellement attrayante. Ensemble, ils forment une puissante boîte à outils pour mieux comprendre ce qu'il y a à l'intérieur de grands ensembles de documents et pour explorer des sous-ensembles de textes connexes. Si ces résultats sont souvent déjà très révélateurs, il est également possible de les utiliser comme point de départ, par exemple pour un exercice d'étiquetage pour la classification supervisée de textes. En somme, les modèles thématiques devraient figurer dans la boîte à outils de chaque data scientist comme un moyen très rapide d'obtenir un aperçu des grandes collections de documents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "*inspiré des résultats de [nlptown](https://github.com/nlptown)*"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Diaporama",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
